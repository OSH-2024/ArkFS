# **可行性报告**

## 小组成员 
* 队长：杨柄权
* 队员：常圣、李岱峰、刘明乐

## 目录

- [**可行性报告**](#可行性报告)
  - [小组成员](#小组成员)
  - [目录](#目录)
  - [**1 概述**](#1-概述)
  - [**2 需求分析**](#2-需求分析)
    - [2.1 优化文件组织](#21-优化文件组织)
    - [2.2 共享存储](#22-共享存储)
    - [2.3 本地与云端相结合](#23-本地与云端相结合)
    - [2.4 文件安全](#24-文件安全)
  - [**3 技术可行性**](#3-技术可行性)
    - [3.1 大语言模型自身优势](#31-大语言模型自身优势)
    - [3.1.1 文件管理智能化](#311-文件管理智能化)
  - [**4 进度可行性**](#4-进度可行性)
    - [实验步骤](#实验步骤)
  - [**5 风险评估**](#5-风险评估)
  - [**6 结论和建议**](#6-结论和建议)

## **1 概述**

传统文件系统的设计理念是基于文件的存储和管理，但是随着数据量的增长，文件系统的性能和可扩展性受到了严重的挑战。为了解决这一问题，研究人员提出了基于大模型的文件系统设计理念。大模型是一种基于深度学习的技术，可以对海量数据进行高效的处理和管理。大模型的引入为文件系统的设计提供了新的思路，可以有效地提高文件系统的性能和可扩展性。
<br>
本小组拟在AIOS（即大语言模型智能体操作系统）思想的基础上，在应用和内核层面优化文件索引技术、存储结构和数据备份及恢复技术，以提高文件系统的性能和可靠性。
<br>

![An overview of the AIOS architecture, https://arxiv.org/html/2403.16971v2/x2.png](https://arxiv.org/html/2403.16971v2/x2.png)

## **2 需求分析**

### 2.1 优化文件组织

LLM根据文件在一定时空内的使用频率确定文件的存储位置，将热点文件存储在高速存储介质上，将冷门文件存储在低速存储介质上，以提高文件的访问速度。并且，LLM可以根据文件的内容和用户的行为进行文件的自动分类和检索，以提高文件的组织和检索效率。

### 2.2 共享存储

实现LLM agents之间的存储共享，以改进模型的决策能力和调度性能。

### 2.3 本地与云端相结合

将本地数据库与云端相结合，引入Next4的快照备份技术，以加强文件系统的数据备份和恢复能力。

### 2.4 文件安全

引入LLM的自然语言处理技术，对文件进行内容分析和风险评估，以提高文件的安全性。

<br>

## **3 技术可行性**

### 3.1 大语言模型自身优势

### 3.1.1 文件管理智能化

- 文件组织与检索。大语言模型可以自动分析内容，提取包括主题、人物、地点、时间、事件等关键信息，并根据用户意图、上下文和历史行为等进行智能化组织和推荐。以下是使用Transformers库中pipeline模块进行零样本分类的示例代码：

```python
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
classifier(
    "This is a course about the Transformers library",
    candidate_labels=["education", "politics", "business"],
)
```

```
{'sequence': 'This is a course about the Transformers library',
 'labels': ['education', 'business', 'politics'],
 'scores': [0.8445963859558105, 0.111976258456707, 0.043427448719739914]}
```

从上述运行结果，我们看到，模型将输入文本分类为“education”类别的概率最高，为0.8446。这种零样本分类技术可以应用于文件管理系统中，以实现文件的自动分类和检索。

- 自动化文件管理。大语言模型可以根据用户的行为和历史记录，自动化地对文件存储、备份、恢复和共享，提升用户的工作效率。如，用户在编辑器中输入“保存文件”命令时，模型可以自动将文件保存到云端，并生成文件的快照备份。

- 保障文件安全。一方面，大语言模型可以通过对文件内容进行语义分析来判断文件的风险等级，设置其访问权限；另一方面，模型也可以对用户的文件行为进行监控，及时发现异常行为，保障文件的安全性。下面展示的是使用Transformers库中pipeline模块进行简单的情感分析和命名实体识别的示例代码：

```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier("I've been waiting for a HuggingFace course my whole life.")
```

```
[{'label': 'POSITIVE', 'score': 0.9598047137260437}]
```

```python
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

```
[{'entity_group': 'PER', 'score': 0.99816, 'word': 'Sylvain', 'start': 11, 'end': 18}, 
 {'entity_group': 'ORG', 'score': 0.97960, 'word': 'Hugging Face', 'start': 33, 'end': 45}, 
 {'entity_group': 'LOC', 'score': 0.99321, 'word': 'Brooklyn', 'start': 49, 'end': 57}
]
```

从上述运行结果，我们看到，模型将输入文本判断为“POSITIVE”情感，且识别出了“Sylvain”为人名、 “Hugging Face”为组织名、 “Brooklyn”为地名。这种情感分析和命名实体识别技术可以应用于文件管理系统中，以实现对文件内容的风险评估和访问控制。

<br>

## **4 进度可行性**

- 项目的时间安排是否合理以及当前结果
  
### 实验步骤

> 1. 挑选适合的`linux`内核编译器，编译`AIOS`提供的内核
> 2. 试用一些自带的`syscall`来完成文件操作，调查那些相关的`SDK`
> 3. 理解新内核`syscall`的原理，分析优化可行性
> 4. 利用`C++`或`python`进行部分`syscall`的优化
> 5. 比对优化前后变化，验证通过`syscall`是否可以高效有序的调用`LLM`

- 验证方法
  
   - 观察AIOS提供的内核是否可用，其大模型集成效果：
  在安装并配置好AIOS提供的内核后，确保系统能够正常启动，并且能够运行常见的任务和应用程序。
测试AIOS内核的大模型集成效果，例如是否能够顺利运行需要大量计算资源和内存的机器学习模型，以及模型的运行性能和准确性如何。
实验新syscall是否可以正常运行，其内置LLM是否可用：

   - 编写简单的程序来测试新的系统调用，确保其可以正常调用并执行所需的功能。
在调用新的系统调用时，观察系统的行为，包括内核日志和系统性能指标，以确保调用过程中没有出现异常或错误。
如果新的系统调用涉及到内置的LLM（例如Gemini/OpenAI API），确保在调用过程中能够正常访问和使用LLM，并且能够获取正确的结果。
对比程序自己编写，主要通过同一文件索引计时对比：

   - 编写自己的程序来执行与新系统调用相同的功能，例如文件操作或LLM访问，并记录执行时间。
使用相同的文件或任务，分别调用新系统调用和自己编写的程序，并记录它们的执行时间。
对比两种方法的执行时间和性能，评估新系统调用的效率和性能优劣。
  

<br>

## **5 风险评估**

- 项目实施过程中可能遇到的风险以及应对计划

<br>

## **6 结论和建议**

- 总结可行性分析的结果。
- 对项目的实施提出建议。

经过一个月的调研与讨论，我们发现了目前大模型和OS结合的前沿方向，并获得了前人宝贵的开发经验。在此基础上，我们认为我们可以通过更进一步的开发，增加OS的功能，尤其是文件系统的相关功能。我们设计了实验，打算从AIOS提供的基础版LLM+OS出发，优化一些SDK，并尝试新增一些syscall，来验证我们的工作是可行的，大模型是可以进一步融入文件系统的管理的，相关功能(文件自动归档、依靠大模型搜索文件)是有希望实现的。

<br>
